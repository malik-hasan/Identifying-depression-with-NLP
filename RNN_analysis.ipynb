{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with Recurrent Neural Networks\n",
    "\n",
    "(this model was unsuccessful at providing meaningful results)\n",
    "\n",
    "We used the pytorch module to implement this Neural network by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import timeit\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gensim\n",
    "import random\n",
    "from nltk.tokenize.casual import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600498\n",
      "1600359\n",
      "[4 0]\n",
      "   target  id                          date     flag      user  \\\n",
      "0       4   3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
      "1       4   4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
      "2       4   5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
      "3       4   6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
      "4       4   7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
      "\n",
      "                                                text  \\\n",
      "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
      "1  Reading my kindle2...  Love it... Lee childs i...   \n",
      "2  Ok, first assesment of the #kindle2 ...it fuck...   \n",
      "3  @kenburbary You'll love your Kindle2. I've had...   \n",
      "4  @mikefish  Fair enough. But i have the Kindle2...   \n",
      "\n",
      "                                               words  num_words  \n",
      "0  (I, loooooooovvvvvveee, my, Kindle, 2, ., Not,...         23  \n",
      "1  (Reading, my, kindle, 2, ..., Love, it, ..., L...         14  \n",
      "2  (Ok, ,, first, assesment, of, the, #kindle2, ....         14  \n",
      "3  (You'll, love, your, Kindle, 2, ., I've, had, ...         31  \n",
      "4  (Fair, enough, ., But, i, have, the, Kindle, 2...         15  \n"
     ]
    }
   ],
   "source": [
    "#read in data\n",
    "df = pd.read_csv('../Downloads/sentiment140.csv', header = None, encoding = \"ISO-8859-1\")\n",
    "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text'] #set column names\n",
    "print(len(df))\n",
    "\n",
    "#removing neutrals because they are very few\n",
    "df = df.drop(df[df.target == 2].index)\n",
    "print(len(df))\n",
    "print(df.target.unique())\n",
    "\n",
    "#add column with tweets tokenized\n",
    "df[\"words\"] = [tuple([word for word in casual_tokenize(row.text) if not re.match('@', \n",
    "  word)]) for _, row in df.iterrows()]\n",
    "df[\"num_words\"] = [len(row.words) for _, row in df.iterrows()]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440323 160036\n",
      "    target   id                          date       flag            user  \\\n",
      "32       4  118  Sat May 16 16:19:04 UTC 2009     google          J_Holl   \n",
      "34       0  120  Sat May 16 16:25:41 UTC 2009        aig        schroncd   \n",
      "77       4  195  Sun May 24 16:19:04 UTC 2009        50d   justinbettman   \n",
      "92       0  214  Mon May 25 17:26:50 UTC 2009    insects  AntoineTheReaL   \n",
      "95       4  217  Mon May 25 17:29:39 UTC 2009  mcdonalds       MamiYessi   \n",
      "\n",
      "                                                 text  \\\n",
      "32  @phyreman9 Google is always a good place to lo...   \n",
      "34  US planning to resume the military tribunals a...   \n",
      "77      Class... The 50d is supposed to come today :)   \n",
      "92  wish i could catch every mosquito in the world...   \n",
      "95  omgg i ohhdee want mcdonalds damn i wonder if ...   \n",
      "\n",
      "                                                words  num_words  prediction  \n",
      "32  (Google, is, always, a, good, place, to, look,...         22         NaN  \n",
      "34  (US, planning, to, resume, the, military, trib...         25         NaN  \n",
      "77  (Class, ..., The, 50d, is, supposed, to, come,...         10         NaN  \n",
      "92  (wish, i, could, catch, every, mosquito, in, t...         25         NaN  \n",
      "95  (omgg, i, ohhdee, want, mcdonalds, damn, i, wo...         13         NaN  \n"
     ]
    }
   ],
   "source": [
    "#split testing and training sets\n",
    "train = df.sample(frac=.9)\n",
    "test = df.drop(train.index)\n",
    "test['prediction'] = np.nan\n",
    "print(len(train), len(test))\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried two different methods of word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(466243, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "466243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word embedding method 1\n",
    "#word to index embedding\n",
    "#vocab dictionary {word: index} \n",
    "word_to_ix = {}\n",
    "ix = 0\n",
    "for _, tweet in train.iterrows():\n",
    "   for word in tweet.words:\n",
    "       if word not in word_to_ix:\n",
    "           word_to_ix[word] = ix\n",
    "           ix += 1\n",
    "word_to_ix[\"__dummy__\"] = ix\n",
    "#use word to index dictionary to create word embeddings\n",
    "embeds = nn.Embedding(len(word_to_ix), 100)  # n words in vocab, 150 dimensional embeddings\n",
    "print(embeds)\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(501414228, 681274048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#word embedding method 2\n",
    "#word-to-vector model\n",
    "W2V_SIZE = 150\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "documents = train.words.tolist()\n",
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)\n",
    "w2v_model.build_vocab(documents)\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we defined the model and some functions to embed and back propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a recurrent neural network model using pytorch\n",
    "class model(nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_output):\n",
    "        super(model, self).__init__()\n",
    "        self.rnn = nn.GRU(num_input, num_hidden)\n",
    "        self.linear = nn.Linear(num_hidden, num_output)\n",
    "        self.activate = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        _, last_hidden = self.rnn(x)\n",
    "        z = self.linear(last_hidden)\n",
    "        y_ = self.activate(z)\n",
    "        return y_[0]\n",
    "\n",
    "def embed(batch):\n",
    "    \"\"\"converts batch of tweets into word embeddings\"\"\"\n",
    "    x, y = [], []\n",
    "    for _, tweet in batch.iterrows():\n",
    "        embedding = []\n",
    "        for word in tweet.words:\n",
    "#using word embedding method 2\n",
    "            if word in w2v_model:\n",
    "                embedding.append(w2v_model[word])\n",
    "            else:\n",
    "                embedding.append([random.uniform(-4, 4) for i in range(150)])\n",
    "        x.append(embedding)\n",
    "##alternate method using word embedding method 1\n",
    "#            if word in word_to_ix:\n",
    "#                lookup_tensor = torch.tensor([word_to_ix[word]], dtype=torch.long)\n",
    "#            else:\n",
    "#                lookup_tensor = [random.random \n",
    "#            word_embed = embeds(lookup_tensor).tolist()[0]\n",
    "#            embedding.append(word_embed)\n",
    "#        x.append(embedding)\n",
    "        y.append([tweet.target != 0])\n",
    "    x = torch.FloatTensor(x) #(len(tweet), 150, 150)\n",
    "    x = x.transpose(0, 1)\n",
    "    y = torch.FloatTensor(y)\n",
    "    return x, y\n",
    "\n",
    "def back_propagate(x, y, m):\n",
    "    \"\"\"trains the rnn model\"\"\"\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.SGD(m.parameters(), lr=0.01)\n",
    "    for epoch in range(1000):\n",
    "        m.zero_grad()\n",
    "        y_ = m(x) # HK\n",
    "        loss = loss_function(y_, y) # HK\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = model(150, 100, 1) #initiate model\n",
    "\n",
    "#train the model in batches of up to 150 tweets at a time\n",
    "begin, end = 1, 101\n",
    "for length in range(begin, end): #I ommitted all the tweets with >100 words because they were mostly gibberish\n",
    "    megabatch = train[train.num_words == length]\n",
    "    if len(megabatch) == 0:\n",
    "        continue\n",
    "\n",
    "    while len(megabatch) > 2000:\n",
    "        batch = megabatch.sample(2000)\n",
    "        megabatch = megabatch.drop(batch.index)\n",
    "        x, y = embed(batch)\n",
    "        m = back_propagate(x, y, m)\n",
    "    x, y = embed(megabatch)\n",
    "    m = back_propagate(x, y, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate the results using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate = 0\n",
    "for length in range(1, 101): #I ommitted all the tweets with >100 words because they were mostly gibberish\n",
    "    megabatch = test[test.num_words == length]\n",
    "    if len(megabatch) == 0:\n",
    "        continue\n",
    "    x, y = embed(megabatch)\n",
    "    y_ = m(x)\n",
    "    for i in range(len(y)):\n",
    "        prediction = round(float(y_[i]))\n",
    "        #test.loc[megabatch.index[i], 'prediction'] = prediction\n",
    "        if y[i] == prediction:\n",
    "            accurate += 1\n",
    "    break\n",
    "print(\"Accuracy: \", accurate/len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
